{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeVideoClip, TextClip, CompositeAudioClip\n",
    "import random\n",
    "from openai import OpenAI\n",
    "from pytube import YouTube\n",
    "from tiktok_uploader.upload import upload_video\n",
    "import whisper\n",
    "from whisper.utils import get_writer\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import customtkinter as ctk\n",
    "import os\n",
    "import string\n",
    "ctk.set_appearance_mode(\"System\")\n",
    "ctk.set_default_color_theme(\"dark-blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_yt_video(link, name, path = ''):\n",
    "\n",
    "    print(\"STEP 1 - Downloading background video\")\n",
    "\n",
    "    video = YouTube(link)\n",
    "    stream = video.streams.get_highest_resolution()\n",
    "    stream.download(path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# GENERATION D'HISTOIRE ###############################\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def GetStory(prompt = \"Raconte une andecdote réelle qui est arrivée dans l'histoire. raconte de facon extremement simple, il faut que le lecteur comprenne tout sans contexte et qu'il soit très intrigué par la première phrase de l'histoire. L'histoire doit avoir du sens, être longue, respecter les 5 étapes d'un récit : la situation initiale, l'élément modificateur, les péripéties, l'élément rééquilibrant, la situation finale.\"):\n",
    "\n",
    "    print(\"STEP 2 - Generating a story\")\n",
    "\n",
    "    less2500 = False\n",
    "    text = \"\"\n",
    "\n",
    "    while not less2500 :\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt + \"\\nTu devras également donner un titre aguicheur, qui invite le lecteur à découvrir la fin de la vidéo.\\nA la suite de ce titre, tu donneras une série de hashtags très connus sur la plateforme TikTok, les hashtags doivent être en rapport avec l'histoire, tu dois en mettre au moins 10.\\nLa réponse doit être sous format JSON en séparant 'hisoire' et 'titre', les hastags seront dans le string 'titre'. Le format sera donc {'histoire': 'histoire longue au format string, sans le titre, ni les hastags','titre': 'le titre suivi des hashtags (les hashatags sont séparés par des espaces)'}\",\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        try :\n",
    "            result = json.loads(chat_completion.choices[0].message.content)\n",
    "            text = result[\"histoire\"] + \" Abonne toi pour la suite !\"\n",
    "            if len(text) <= 2500 :\n",
    "                less2500 = True\n",
    "            else :\n",
    "                print(\"Story is too long, a new one is being generated !\")\n",
    "        except :\n",
    "            print(\"Impossible to parse, a new story is being generated !\")\n",
    "\n",
    "\n",
    "\n",
    "    return text, result[\"titre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# TEXT TO SPEECH ###############################\n",
    "\n",
    "def generate_speech(text_prompt,output_path) :\n",
    "\n",
    "     print(\"STEP 3 - Generating speech\")\n",
    "\n",
    "     driver=webdriver.Chrome()\n",
    "\n",
    "     driver.get(\"https://freetools.textmagic.com/text-to-speech\")\n",
    "     driver.maximize_window()\n",
    "\n",
    "     driver.find_element(By.XPATH, '/html/body/div[2]/div/section/div/div[2]/textarea').clear()\n",
    "     driver.find_element(By.XPATH, '/html/body/div[2]/div/section/div/div[2]/textarea').send_keys(text_prompt)\n",
    "     elem = driver.find_element(By.XPATH, '/html/body/div[2]/div/section/div/div[1]/div/div[1]/button')\n",
    "     elem.click()\n",
    "     driver.find_element(By.XPATH, '/html/body/div[2]/div/section/div/div[1]/div/div[1]/ul/li[159]/a').click()\n",
    "\n",
    "     elem = driver.find_element(By.XPATH, '/html/body/div[2]/div/section/div/div[3]/button[2]')\n",
    "\n",
    "     ac = ActionChains(driver)\n",
    "     driver.execute_script(\"window.scrollBy(0, 400);\")\n",
    "\n",
    "     ac.move_to_element(elem).move_by_offset(-150,50).click().perform()\n",
    "\n",
    "     #download\n",
    "     time.sleep(30)\n",
    "     driver.find_element(By.XPATH, '/html/body/div[2]/div/section/div/div[3]/button[2]').click()\n",
    "     current_datetime = datetime.now()\n",
    "     time.sleep(30)\n",
    "\n",
    "     # Format the date and time as per your requirement\n",
    "     formatted_datetime = current_datetime.strftime(\"%d-%b-%Y_%H-%M\")\n",
    "\n",
    "     src_path = \"C:/Users/henri/Downloads/Text-to-Speech_\" + formatted_datetime + \".mp3\"\n",
    "     dst_path = output_path\n",
    "     shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# SOUS TITRAGE ###############################\n",
    "\n",
    "model_name = \"large\"\n",
    "model = whisper.load_model(model_name, download_root=\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_srt(audio_name):\n",
    "\n",
    "    audio_path = \"../outputs/audio_outputs/\"+audio_name+\".mp3\"\n",
    "    audio = whisper.load_audio(audio_path)\n",
    "    result = whisper.transcribe(model, audio, word_timestamps=True, language='fr')\n",
    "\n",
    "    srt_writer = get_writer(\"srt\", \"../outputs/srt_outputs/\")\n",
    "    srt_writer(result, audio_path, {\"max_line_width\": 16, \"max_line_count\": 1})\n",
    "    srt_writer(result, \"../outputs/audio_outputs/\"+audio_name+\"_words.mp3\", {\"max_words_per_line\": 1})\n",
    "\n",
    "def afficher_srt(chemin_fichier):\n",
    "    sous_titres = []\n",
    "    try:\n",
    "        with open(chemin_fichier, 'r', encoding='utf-8') as fichier:\n",
    "            bloc = []\n",
    "            for ligne in fichier:\n",
    "                if ligne.strip() == '':\n",
    "                    if bloc:\n",
    "                        sous_titres.append(bloc)\n",
    "                        bloc = []\n",
    "                elif '-->' in ligne:\n",
    "                    temps = ligne.split('-->')\n",
    "                    temps_debut = temps[0].strip()\n",
    "                    temps_fin = temps[1].strip()\n",
    "                    bloc.append(temps_debut)\n",
    "                    bloc.append(temps_fin)\n",
    "                elif bloc:\n",
    "                    bloc.append(ligne.strip())\n",
    "    except FileNotFoundError:\n",
    "        print(\"Le fichier n'a pas été trouvé.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite: {e}\")\n",
    "\n",
    "    return sous_titres\n",
    "\n",
    "\n",
    "def convertir_timestamp_en_secondes(timestamp):\n",
    "    heures, minutes, rest = timestamp.split(':')\n",
    "    secondes, millisecondes = rest.split(',')\n",
    "    temps_total = int(heures) * 3600 + int(minutes) * 60 + int(secondes) + int(millisecondes) / 1000\n",
    "    return temps_total\n",
    "\n",
    "\n",
    "def choisir_aleatoirement():\n",
    "    green = '#33FF36'\n",
    "    yellow = '#FFEC33'\n",
    "    red = '#FF5733'\n",
    "    return random.choice([green, yellow, red])\n",
    "\n",
    "def remove_punctuation(input_str):\n",
    "    # Supprimer les signes de ponctuation de la chaîne\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return input_str.translate(translator)\n",
    "\n",
    "def are_equal_without_punctuation(str1, str2):\n",
    "    # Supprimer la ponctuation et comparer les chaînes\n",
    "    cleaned_str1 = remove_punctuation(str1)\n",
    "    cleaned_str2 = remove_punctuation(str2)\n",
    "    return cleaned_str1 == cleaned_str2\n",
    "\n",
    "def srt(audio_name, video):\n",
    "    print(\"STEP 5 - Generating subtitles\")\n",
    "\n",
    "    path_font = '../input/fonts/Montserrat-Black.ttf'\n",
    "\n",
    "    get_srt(audio_name)\n",
    "    subtitles = afficher_srt(\"../outputs/srt_outputs/\"+audio_name+\".srt\")\n",
    "    subtitles_precis = afficher_srt(\"../outputs/srt_outputs/\"+audio_name+\"_words.srt\")\n",
    "\n",
    "    shift = 100\n",
    "    shift_2= -66\n",
    "\n",
    "    size_border_1 = 84\n",
    "    size_txt_1 = 63\n",
    "    size_border_2 = 75\n",
    "    size_txt_2 = 57\n",
    "\n",
    "    couleur = 'white'  \n",
    "    contour = 'black'\n",
    "    clips = []\n",
    "    i = 0\n",
    "    for j in range(0, len(subtitles), 2): \n",
    "        sub1 = subtitles[j]\n",
    "        if j + 1 < len(subtitles): \n",
    "            sub2 = subtitles[j+1]\n",
    "        #print('-', sub1[2])\n",
    "        for mot in re.split(r\"[ ' -]\", sub1[2]):\n",
    "            if i<len(subtitles_precis) and are_equal_without_punctuation(mot, subtitles_precis[i][2] ):\n",
    "                mot_highlight = '<span foreground=\"' + choisir_aleatoirement()+'\" >'\n",
    "                mot_highlight += mot.upper()\n",
    "                mot_highlight += '</span>'\n",
    "                texte = sub1[2].upper().replace(mot.upper(), mot_highlight)\n",
    "                if i == 0 : \n",
    "                    start = convertir_timestamp_en_secondes(subtitles_precis[i][0])\n",
    "                else : start = end\n",
    "                end = convertir_timestamp_en_secondes(subtitles_precis[i][1])\n",
    "                #print(start, end, subtitles_precis[i][2])\n",
    "                video_height = video.h \n",
    "                vertical_position = (video_height / 2) -54\n",
    "\n",
    "                txt_ = sub1[2].upper()\n",
    "                border = TextClip(txt_, font=path_font, fontsize=size_border_1, color=couleur, stroke_color=contour, stroke_width=15).set_position(('center', vertical_position)).set_start(start).set_end(end)\n",
    "                txt = TextClip(texte,font=\"Montserrat Black\",  fontsize=size_txt_1, color=couleur, stroke_color=contour, stroke_width=0, method=\"pango\").set_position('center').set_start(start).set_end(end)\n",
    "                    \n",
    "\n",
    "                vertical_position = (video_height / 2) -54 + shift\n",
    "                vertical_position_ = (video_height / 2) +shift_2 + shift\n",
    "                border_2 = TextClip(sub2[2].upper(), font=path_font, fontsize=size_border_2, color=couleur, stroke_color=contour, stroke_width=15).set_position(('center', vertical_position)).set_start(start).set_end(end)\n",
    "                txt_2 = TextClip(sub2[2].upper(),font=\"Montserrat Black\",  fontsize=size_txt_2, color=couleur, stroke_color=contour, stroke_width=0, method=\"pango\").set_position(('center', vertical_position_)).set_start(start).set_end(end)\n",
    "\n",
    "                clips.append(border)\n",
    "                clips.append(txt)\n",
    "                clips.append(border_2)\n",
    "                clips.append(txt_2)\n",
    "\n",
    "                i += 1\n",
    "        #print('--', sub2[2])\n",
    "        for mot in re.split(r\"[ ' -]\", sub2[2]):\n",
    "            if i<len(subtitles_precis) and are_equal_without_punctuation(mot, subtitles_precis[i][2] ):\n",
    "                mot_highlight = '<span foreground=\"' + choisir_aleatoirement()+'\" >'\n",
    "                mot_highlight += mot.upper()\n",
    "                mot_highlight += '</span>'\n",
    "                texte = sub2[2].upper().replace(mot.upper(), mot_highlight)\n",
    "                start = end\n",
    "                end = convertir_timestamp_en_secondes(subtitles_precis[i][1])\n",
    "                #print(start, end, subtitles_precis[i][2])\n",
    "                video_height = video.h \n",
    "                vertical_position = (video_height / 2) -54\n",
    "\n",
    "                txt_ = sub2[2].upper()\n",
    "                border = TextClip(sub1[2].upper(), font=path_font, fontsize=size_border_2, color=couleur, stroke_color=contour, stroke_width=15).set_position(('center', vertical_position)).set_start(start).set_end(end)\n",
    "                txt = TextClip(sub1[2].upper(),font=\"Montserrat Black\",  fontsize=size_txt_2, color=couleur, stroke_color=contour, stroke_width=0, method=\"pango\").set_position('center').set_start(start).set_end(end)\n",
    "                    \n",
    "            \n",
    "                vertical_position = (video_height / 2) -54 + shift\n",
    "                vertical_position_ = (video_height / 2) +shift_2 + shift\n",
    "                border_2 = TextClip(txt_ , font=path_font, fontsize=size_border_1, color=couleur, stroke_color=contour, stroke_width=15).set_position(('center', vertical_position)).set_start(start).set_end(end)\n",
    "                txt_2 = TextClip(texte ,font=\"Montserrat Black\",  fontsize=size_txt_1, color=couleur, stroke_color=contour, stroke_width=0, method=\"pango\").set_position(('center', vertical_position_)).set_start(start).set_end(end)\n",
    "\n",
    "                clips.append(border)\n",
    "                clips.append(txt)\n",
    "                clips.append(border_2)\n",
    "                clips.append(txt_2)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    \n",
    "    return CompositeVideoClip([video, *clips ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# MONTAGE VIDEO ###############################\n",
    "\n",
    "def combine_video_audio(final_name, vod_number, music_name=\"solas.mp3\"):\n",
    "\n",
    "    print(\"STEP 4 - Editing the video\")\n",
    "\n",
    "    video_path = \"../input/background/\" + final_name+'_background.mp4'\n",
    "    audio_path = \"../outputs/audio_outputs/\" + final_name + vod_number + \"_audio.mp3\"\n",
    "    output_path = \"../outputs/final_outputs/\" + final_name + vod_number + \".mp4\"\n",
    "\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    video_clip = video_clip.resize((3413, 1920))\n",
    "\n",
    "    # Calculate the center of the video\n",
    "    center_x = video_clip.size[0] // 2\n",
    "    center_y = video_clip.size[1] // 2\n",
    "\n",
    "    # Define the dimensions for cropping (1080x1920)\n",
    "    crop_width = 1080\n",
    "    crop_height = 1920\n",
    "\n",
    "    # Calculate the cropping region\n",
    "    x1 = center_x - crop_width // 2\n",
    "    y1 = center_y - crop_height // 2\n",
    "    x2 = center_x + crop_width // 2\n",
    "    y2 = center_y + crop_height // 2\n",
    "\n",
    "    # Crop the video clip\n",
    "    video_clip = video_clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)\n",
    "\n",
    "    # Resize the cropped clip to 1080x1920 if needed\n",
    "    #video_clip = video_clip.resize((1080, 1920))\n",
    "\n",
    "    # Load audio clip\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "\n",
    "    #Here, we will cut the video randomly so that it matches the audio duration\n",
    "    video_duration = round(video_clip.duration)\n",
    "    audio_duration = round(audio_clip.duration)\n",
    "    diff = video_duration - audio_duration-1\n",
    "\n",
    "    if diff < 0 :\n",
    "        raise Exception(\"**** ERROR la video donnée est plus courte que l'audio généré *****\")\n",
    "\n",
    "    start = random.randint(0, diff)\n",
    "\n",
    "    # Trim video based on start and end times\n",
    "    video_clip = video_clip.subclip(start)\n",
    "    video_clip = video_clip.set_duration(audio_clip.duration)\n",
    "\n",
    "    video_final = srt(final_name + vod_number+\"_audio\", video_clip)\n",
    "\n",
    "    #adding the music\n",
    "\n",
    "    # Load audio clip\n",
    "    # Load audio clip\n",
    "    music = AudioFileClip(\"../input/music/\"+music_name)\n",
    "    music = music.subclip(6).volumex(0.5)\n",
    "    music = music.set_duration(video_final.duration)\n",
    "\n",
    "    new_audioclip = CompositeAudioClip([music, audio_clip])\n",
    "    video_final.audio = new_audioclip\n",
    "    \n",
    "    print(\"STEP 6 - Exporting video\")\n",
    "\n",
    "    video_final.write_videofile(output_path, codec=\"libx264\", bitrate=\"8000k\", temp_audiofile=\"temp-audio.m4a\", remove_temp=True, audio_codec=\"aac\")\n",
    "\n",
    "    video_clip.close()\n",
    "    video_final.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_tiktok(path_to_video:str, description:str)->str:\n",
    "\n",
    "    print(\"STEP 7 - Uploading on TikTok\")\n",
    "\n",
    "    upload_video(path_to_video, \n",
    "    description=description, \n",
    "    cookies='tiktok_cookies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_video_link = 'https://www.youtube.com/watch?v=ZkHKGWKq9mY'\n",
    "name_of_result = \"gta\"\n",
    "number_of_toktok = 1\n",
    "prompt = \"Raconte une andecdote réelle qui est arrivée dans l'histoire. raconte de facon extremement simple, il faut que le lecteur comprenne tout sans contexte et qu'il soit très intrigué par la première phrase de l'histoire. L'histoire doit avoir du sens et respecter les 5 étapes d'un récit : la situation initiale très rapidemnt, l'élément déclencheur (très intriguant, qui suscite l'impatience du lecteur'), les péripéties innatendues, la situation finale.\"\n",
    "\n",
    "def create_videos(background_link, name_of_result, number, prompt):\n",
    "    download_yt_video(link = background_link, name = name_of_result+'_background.mp4', path=\"../input/background/\")\n",
    "    for i in range(number):\n",
    "        input_audio_path = \"../outputs/audio_outputs/\" + name_of_result + str(i) + \"_audio.mp3\"\n",
    "        text, titre = GetStory(prompt)\n",
    "        generate_speech(text, input_audio_path)\n",
    "        combine_video_audio(name_of_result,str(i))\n",
    "        df = pd.read_csv('../outputs/titres.csv')\n",
    "        new_row = pd.DataFrame({'vod_name': [name_of_result+str(i)+\".mp4\"], 'titre': [titre]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df.to_csv('../outputs/titres.csv', index=False)\n",
    "        print(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post():\n",
    "    files = os.listdir(\"../outputs/final_outputs\")\n",
    "    if len(files)!=0:\n",
    "        path = random.choice(files)\n",
    "        df = pd.read_csv('../outputs/titres.csv')\n",
    "        description = df.loc[df['vod_name'] == path, 'titre'].iloc[0]\n",
    "\n",
    "        print(path, description)\n",
    "        #publish_tiktok(\"../outputs/final_outputs/\" + path, description)\n",
    "        #shutil.move(\"../outputs/final_outputs/\" + path, \"../outputs/published/\" + path)\n",
    "\n",
    "post()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\tkinter\\__init__.py\", line 1889, in __call__\n",
      "    try:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "w=600\n",
    "\n",
    "class App(ctk.CTk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # configure window\n",
    "        self.title(\"TikTouk.py\")\n",
    "        self.geometry(f\"{711}x{500}\")\n",
    "\n",
    "        self.grid_columnconfigure(1, weight=1)\n",
    "        self.grid_columnconfigure((2, 3), weight=0)\n",
    "        self.grid_rowconfigure((0, 1, 2), weight=1)\n",
    "\n",
    "        # Configuration des styles pour ttk.Notebook\n",
    "        style = ttk.Style()\n",
    "        style.theme_use('default')\n",
    "        style.configure(\"TNotebook.Tab\", background=\"black\", foreground=\"black\", padding=[5, 2])\n",
    "\n",
    "        self.notebook = ttk.Notebook(self)\n",
    "        self.notebook.grid(row=0, column=0, columnspan=2, rowspan=3, sticky=\"nesw\")\n",
    "\n",
    "        self.tab1 = ctk.CTkFrame(self.notebook)\n",
    "        self.notebook.add(self.tab1, text=\"Histoire\")\n",
    "        self.entry_url_yt = ctk.CTkEntry(self.tab1, placeholder_text=\"Background YouTube\", width=300)\n",
    "        self.entry_url_yt.pack(pady=(50, 5))\n",
    "        self.entry_nb_video = ctk.CTkEntry(self.tab1, placeholder_text=\"Number\", width=100)\n",
    "        self.entry_nb_video.pack(pady=5)\n",
    "        self.name = ctk.CTkEntry(self.tab1, placeholder_text=\"Enter name for video series\", width=200)\n",
    "        self.name.pack(pady= 5)\n",
    "        button = ctk.CTkButton(self.tab1, text=\"Generate Video(s)\", command = lambda : create_videos(self.entry_url_yt.get(), self.name.get(), int(self.entry_nb_video.get()), self.prompt_story.get(\"1.0\", \"end-1c\")))\n",
    "        button.pack(pady=5)\n",
    "        button = ctk.CTkButton(self.tab1, text=\"Upload last video\", command = lambda : post())\n",
    "        button.pack(pady=5)\n",
    "        nb_video_prete = ctk.CTkLabel(self.tab1, text= \"Videos ready : \" + str(number_available))\n",
    "        nb_video_prete.pack(pady = 5)\n",
    "        self.prompt_story = ctk.CTkTextbox(self.tab1, width=500)\n",
    "        self.prompt_story.pack(pady = 5)\n",
    "        self.prompt_story.insert(\"1.0\", prompt)\n",
    "        self.tab2 = ctk.CTkFrame(self.notebook)\n",
    "        self.notebook.add(self.tab2, text=\"Ted X\")\n",
    "        entry_url_yt_tedX = ctk.CTkEntry(self.tab2, placeholder_text=\"Coller un url YT\")\n",
    "        entry_url_yt_tedX.pack(pady=(50, 10))\n",
    "        self.entry_nb_video_tedX = ctk.CTkEntry(self.tab2, placeholder_text=\"nombre de video\")\n",
    "        self.entry_nb_video_tedX.pack(pady=10)\n",
    "        button = ctk.CTkButton(self.tab2, text=\"Export Vidéo\", command = lambda : download_yt_video(link = entry_url_yt.get()))\n",
    "        button.pack(pady=10)\n",
    "        button = ctk.CTkButton(self.tab2, text=\"Poster last video\", command = lambda : post())\n",
    "        button.pack(pady=10)\n",
    "        nb_video_prete = ctk.CTkLabel(self.tab2, text= \"Nb vidéo pretes : 0\")\n",
    "        nb_video_prete.pack(pady = 10)\n",
    "        self.prompt_tedX = ctk.CTkTextbox(self.tab2)\n",
    "        self.prompt_tedX.pack(pady = 10)\n",
    "\n",
    "    def load_session(self): \n",
    "        return 0\n",
    "    \n",
    "    def save_session(self): \n",
    "        return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = os.listdir(\"../outputs/final_outputs\")\n",
    "    number_available = len(files)\n",
    "    app = App()\n",
    "    app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_video_link = \"https://www.youtube.com/watch?v=GVdso1AD00Y\"\n",
    "# def get_music(background_video_link):\n",
    "#     video = YouTube(background_video_link)\n",
    "#     stream = video.streams.filter(only_audio=True).first()\n",
    "#     stream.download(output_path=\"../input/music\", filename=\"solas.mp3\")\n",
    "\n",
    "# music_name = \"solas.mp3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.config import change_settings\n",
    "# change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
